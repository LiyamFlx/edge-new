<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EngageSense</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        /* General Styles */
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background: linear-gradient(120deg, #1e1e2f, #2c2c44);
            color: #ffffff;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            display: none;
        }

        .container.active {
            display: block;
        }

        h1 {
            font-size: 28px;
            text-align: center;
            margin-bottom: 20px;
        }

        p {
            font-size: 16px;
            text-align: center;
            margin-bottom: 30px;
        }

        .buttons button {
            margin: 10px 5px;
        }

        .progress-bar-wrapper {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            height: 10px;
            background: rgba(255, 255, 255, 0.2);
        }

        .progress-bar-inner {
            height: 100%;
            background: #00aaff;
            width: 0%;
            transition: width 0.5s ease;
        }

        canvas {
            display: block;
            margin: 20px auto;
            background: white;
            border-radius: 8px;
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            background-color: #00aaff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        button[disabled] {
            background-color: #555;
            cursor: not-allowed;
        }

        button:hover:enabled {
            background-color: #007acc;
        }
    </style>
</head>
<body>
    <!-- Upload/Record Audio Screen -->
    <div class="container active" id="upload-record-screen">
        <h1>Upload or Record Audio</h1>
        <p>Upload an audio file or record live with real-time visualization.</p>
        <div>
            <h2>Upload Track</h2>
            <input type="file" id="upload-input" accept=".mp3,.mp4">
            <button id="analyze-upload-btn" disabled onclick="analyzeUpload()">Analyze Upload</button>
        </div>
        <div>
            <h2>Record Audio</h2>
            <div class="buttons">
                <button id="start-record-btn">Start Recording</button>
                <button id="stop-record-btn" disabled>Stop Recording</button>
            </div>
            <canvas id="record-waveform" width="600" height="200"></canvas>
            <button id="analyze-record-btn" disabled onclick="analyzeRecording()">Analyze Recording</button>
        </div>
        <div class="navigation">
            <button onclick="navigate('welcome-screen')">← Back</button>
            <button onclick="navigate('analysis-screen')">Next →</button>
        </div>
    </div>

    <!-- Progress Bar -->
    <div class="progress-bar-wrapper">
        <div class="progress-bar-inner" id="progress-bar"></div>
    </div>

    <script>
        // Navigation between screens
        function navigate(screenId) {
            document.querySelectorAll('.container').forEach(container => {
                container.classList.remove('active');
            });
            document.getElementById(screenId).classList.add('active');
        }

        // Progress bar control
        function updateProgressBar(percentage) {
            const progressBar = document.getElementById('progress-bar');
            progressBar.style.width = percentage + '%';
        }

        // File Upload Handling
        const uploadInput = document.getElementById('upload-input');
        const analyzeUploadBtn = document.getElementById('analyze-upload-btn');

        uploadInput.addEventListener('change', () => {
            if (uploadInput.files.length > 0) {
                analyzeUploadBtn.disabled = false; // Enable Analyze Upload button
            }
        });

        function analyzeUpload() {
            updateProgressBar(50);
            alert('Analyzing uploaded audio...');
            setTimeout(() => {
                updateProgressBar(100);
                alert('Analysis complete!');
                navigate('results-screen'); // Navigate to results screen
            }, 2000);
        }

        // Recording Functionality
        const startRecordBtn = document.getElementById('start-record-btn');
        const stopRecordBtn = document.getElementById('stop-record-btn');
        const analyzeRecordBtn = document.getElementById('analyze-record-btn');
        const canvas = document.getElementById('record-waveform');
        const canvasContext = canvas.getContext('2d');

        let audioContext, analyser, dataArray, bufferLength, mediaRecorder, audioStream;

        startRecordBtn.addEventListener('click', async () => {
            audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            const source = audioContext.createMediaStreamSource(audioStream);
            source.connect(analyser);
            analyser.fftSize = 256;
            bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            mediaRecorder = new MediaRecorder(audioStream);
            mediaRecorder.start();

            startRecordBtn.disabled = true;
            stopRecordBtn.disabled = false;

            visualizeWaveform();
        });

        stopRecordBtn.addEventListener('click', () => {
            if (mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                audioStream.getTracks().forEach(track => track.stop());
                startRecordBtn.disabled = false;
                stopRecordBtn.disabled = true;
                analyzeRecordBtn.disabled = false; // Enable Analyze Recording button
            }
        });

        function analyzeRecording() {
            updateProgressBar(50);
            alert('Analyzing recorded audio...');
            setTimeout(() => {
                updateProgressBar(100);
                alert('Analysis complete!');
                navigate('results-screen'); // Navigate to results screen
            }, 2000);
        }

        // Visualize Waveform
        function visualizeWaveform() {
            canvasContext.clearRect(0, 0, canvas.width, canvas.height);
            analyser.getByteTimeDomainData(dataArray);

            canvasContext.lineWidth = 2;
            canvasContext.strokeStyle = '#00aaff';
            canvasContext.beginPath();

            const sliceWidth = canvas.width / bufferLength;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = (v * canvas.height) / 2;

                if (i === 0) {
                    canvasContext.moveTo(x, y);
                } else {
                    canvasContext.lineTo(x, y);
                }

                x += sliceWidth;
            }

            canvasContext.lineTo(canvas.width, canvas.height / 2);
            canvasContext.stroke();

            requestAnimationFrame(visualizeWaveform);
        }
    </script>
</body>
</html>
